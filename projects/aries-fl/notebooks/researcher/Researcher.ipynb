{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "educational-bunch",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IPython autoawait is `on`, and set to use `asyncio`\n"
     ]
    }
   ],
   "source": [
    "%autoawait\n",
    "import time\n",
    "import asyncio\n",
    "from aries_basic_controller.aries_controller import AriesAgentController\n",
    "    \n",
    "WEBHOOK_HOST = \"0.0.0.0\"\n",
    "WEBHOOK_PORT = 8042\n",
    "WEBHOOK_BASE = \"\"\n",
    "# ADMIN_URL = \"http://researcher-agent:8041\"\n",
    "ADMIN_URL = \"http://0.0.0.0:8041\"\n",
    "\n",
    "\n",
    "# Based on the aca-py agent you wish to control\n",
    "agent_controller = AriesAgentController(webhook_host=WEBHOOK_HOST, webhook_port=WEBHOOK_PORT,\n",
    "                                       webhook_base=WEBHOOK_BASE, admin_url=ADMIN_URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "silent-treasurer",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-34' coro=<AriesAgentController.listen_webhooks() done, defined at /Users/pavlito/miniconda3/envs/pydentity-dev/lib/python3.8/site-packages/aries_basic_controller/aries_controller.py:92> exception=OSError(48, \"error while attempting to bind on address ('0.0.0.0', 8042): address already in use\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/pavlito/miniconda3/envs/pydentity-dev/lib/python3.8/site-packages/aries_basic_controller/aries_controller.py\", line 98, in listen_webhooks\n",
      "    await self.webhook_site.start()\n",
      "  File \"/Users/pavlito/miniconda3/envs/pydentity-dev/lib/python3.8/site-packages/aiohttp/web_runner.py\", line 100, in start\n",
      "    self._server = await loop.create_server(  # type: ignore\n",
      "  File \"/Users/pavlito/miniconda3/envs/pydentity-dev/lib/python3.8/asyncio/base_events.py\", line 1463, in create_server\n",
      "    raise OSError(err.errno, 'error while attempting '\n",
      "OSError: [Errno 48] error while attempting to bind on address ('0.0.0.0', 8042): address already in use\n"
     ]
    }
   ],
   "source": [
    "\n",
    "loop = asyncio.get_event_loop()\n",
    "loop.create_task(agent_controller.listen_webhooks())\n",
    "\n",
    "def messages_handler(payload):\n",
    "    connection_id = payload[\"connection_id\"]\n",
    "    asyncio.get_event_loop().create_task(agent_controller.messaging.send_message(connection_id, \"This is a response from Bob\"))\n",
    "    print(\"Handle message\", payload, connection_id)\n",
    "\n",
    "\n",
    "message_listener = {\n",
    "    \"handler\": messages_handler,\n",
    "    \"topic\": \"basicmessages\"\n",
    "}\n",
    "\n",
    "\n",
    "def connection_handler(payload):\n",
    "    print(\"Connection Handler Called\")\n",
    "    connection_id = payload[\"connection_id\"]\n",
    "    state = payload[\"state\"]\n",
    "    print(f\"Connection {connection_id} in State {state}\")\n",
    "    \n",
    "connection_listener = {\n",
    "    \"handler\": connection_handler,\n",
    "    \"topic\": \"connections\"\n",
    "}\n",
    "\n",
    "agent_controller.register_listeners([connection_listener, message_listener], defaults=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "present-combat",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection ID c561fe99-d37f-42c0-8703-cca97c0e3e55\n",
      "Invitation\n",
      "{'@type': 'did:sov:BzCbsNYhMrjHiqZDTUASHg;spec/connections/1.0/invitation', '@id': '0ffe0480-5b18-432e-869d-a8d0b44e1095', 'serviceEndpoint': 'http://192.168.65.3:8040', 'recipientKeys': ['9unc3yUPfSsTxM9FsrDmVwFWe3icW3qokVFwiNzNKbhs'], 'label': 'Health Researcher'}\n"
     ]
    }
   ],
   "source": [
    "# Create Invitation\n",
    "invite = await agent_controller.connections.create_invitation()\n",
    "connection_id = invite[\"connection_id\"]\n",
    "invite_message = invite['invitation']\n",
    "print(\"Connection ID\", connection_id)\n",
    "print(\"Invitation\")\n",
    "print(invite_message)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abstract-knife",
   "metadata": {},
   "source": [
    "## Copy the invitation output from 4 and to the hospital notebook you are connecting to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dimensional-chassis",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACCEPT REQUEST\n",
      "{'updated_at': '2021-01-25 11:04:16.830834Z', 'state': 'response', 'connection_id': 'c561fe99-d37f-42c0-8703-cca97c0e3e55', 'created_at': '2021-01-25 11:03:08.736549Z', 'invitation_mode': 'once', 'accept': 'manual', 'their_did': '7vWuaxg22g8mo7WBS1e8vn', 'initiator': 'self', 'invitation_key': '9unc3yUPfSsTxM9FsrDmVwFWe3icW3qokVFwiNzNKbhs', 'their_label': 'Royal Infirmary of Edinburgh', 'my_did': 'HicPGhJ8hw9Mcqmj7z5CrF', 'routing_state': 'none'}\n",
      "state response\n"
     ]
    }
   ],
   "source": [
    "# Accept Request for Invite created\n",
    "connection = await agent_controller.connections.accept_request(connection_id)\n",
    "print(\"ACCEPT REQUEST\")\n",
    "print(connection)\n",
    "print(\"state\", connection[\"state\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "published-investing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trust Ping {'thread_id': 'd7a6f6b6-db44-4e9f-a37a-d4b25debecb7'}\n"
     ]
    }
   ],
   "source": [
    "trust_ping = await agent_controller.messaging.trust_ping(connection_id, \"hello\")\n",
    "print(\"Trust Ping\", trust_ping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "underlying-respondent",
   "metadata": {},
   "outputs": [],
   "source": [
    "trust_ping = await agent_controller.messaging.trust_ping(connection_id, \"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "textile-wales",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unclosed client session\n",
      "client_session: <aiohttp.client.ClientSession object at 0x7fdaeeb8ef10>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COORDINATOR IS CLEANING THE VALIDATION SET\n",
      "COORDINATOR DATA                Timestamp  Age  Gender         Country state self_employed  \\\n",
      "0    2014-08-29 09:29:37   25    Male   United States    PA            No   \n",
      "1    2014-08-29 09:31:37   42    male   United States    IN            No   \n",
      "2    2014-08-29 09:31:49   34    male   United States    PA            No   \n",
      "3    2014-08-29 09:33:43   26  female   United States    OH            No   \n",
      "4    2014-08-29 09:35:46   35    Male  United Kingdom   NaN            No   \n",
      "..                   ...  ...     ...             ...   ...           ...   \n",
      "254  2015-09-12 11:17:21   26    male  United Kingdom   NaN            No   \n",
      "255  2015-09-26 01:07:35   32    Male   United States    IL            No   \n",
      "256  2015-11-07 12:36:58   34    male   United States    CA            No   \n",
      "257  2015-11-30 21:25:06   46       f   United States    NC            No   \n",
      "258  2016-02-01 23:04:31   25    Male   United States    IL            No   \n",
      "\n",
      "    family_history treatment work_interfere    no_employees  ...  \\\n",
      "0              Yes       Yes          Often            6-25  ...   \n",
      "1              Yes       Yes      Sometimes            6-25  ...   \n",
      "2              Yes       Yes          Often         100-500  ...   \n",
      "3               No       Yes      Sometimes          26-100  ...   \n",
      "4              Yes       Yes      Sometimes             1-5  ...   \n",
      "..             ...       ...            ...             ...  ...   \n",
      "254             No       Yes            NaN          26-100  ...   \n",
      "255            Yes       Yes          Often          26-100  ...   \n",
      "256            Yes       Yes      Sometimes  More than 1000  ...   \n",
      "257             No        No            NaN         100-500  ...   \n",
      "258            Yes       Yes      Sometimes          26-100  ...   \n",
      "\n",
      "                  leave mental_health_consequence phys_health_consequence  \\\n",
      "0         Somewhat easy                        No                      No   \n",
      "1            Don't know                     Maybe                      No   \n",
      "2             Very easy                        No                      No   \n",
      "3            Don't know                     Maybe                      No   \n",
      "4             Very easy                       Yes                     Yes   \n",
      "..                  ...                       ...                     ...   \n",
      "254       Somewhat easy                        No                      No   \n",
      "255  Somewhat difficult                        No                      No   \n",
      "256  Somewhat difficult                       Yes                     Yes   \n",
      "257          Don't know                       Yes                      No   \n",
      "258          Don't know                     Maybe                      No   \n",
      "\n",
      "        coworkers    supervisor mental_health_interview phys_health_interview  \\\n",
      "0             Yes           Yes                   Maybe                 Maybe   \n",
      "1    Some of them           Yes                      No                 Maybe   \n",
      "2             Yes           Yes                   Maybe                 Maybe   \n",
      "3    Some of them            No                   Maybe                 Maybe   \n",
      "4    Some of them  Some of them                      No                 Maybe   \n",
      "..            ...           ...                     ...                   ...   \n",
      "254  Some of them  Some of them                      No                    No   \n",
      "255  Some of them           Yes                      No                    No   \n",
      "256            No            No                      No                    No   \n",
      "257            No            No                      No                    No   \n",
      "258  Some of them            No                      No                    No   \n",
      "\n",
      "    mental_vs_physical obs_consequence comments  \n",
      "0           Don't know              No      NaN  \n",
      "1           Don't know              No      NaN  \n",
      "2           Don't know              No      NaN  \n",
      "3           Don't know             Yes      NaN  \n",
      "4                  Yes             Yes      NaN  \n",
      "..                 ...             ...      ...  \n",
      "254         Don't know              No      NaN  \n",
      "255                Yes              No      NaN  \n",
      "256                 No              No      NaN  \n",
      "257                 No              No      NaN  \n",
      "258         Don't know              No      NaN  \n",
      "\n",
      "[259 rows x 27 columns]\n",
      "VALIDATION SET HAS BEEN CLEANED\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# models\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.autograd import Variable\n",
    "import os\n",
    "import sys\n",
    "\n",
    "from opacus import PrivacyEngine\n",
    "\n",
    "# The Researcher generates the model\n",
    "\n",
    "# Data pre-processing\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# prep\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.preprocessing import binarize, LabelEncoder, MinMaxScaler\n",
    "from sklearn import metrics\n",
    "\n",
    "print(\"COORDINATOR IS CLEANING THE VALIDATION SET\")\n",
    "\n",
    "#Read in Data\n",
    "train_df = pd.read_csv('coordinator_validation_data.csv')\n",
    "\n",
    "print(\"COORDINATOR DATA\", train_df)\n",
    "\n",
    "########## START DATA CLEANING ###############\n",
    "#Let’s get rid of the variables \"Timestamp\",“comments”, “state” just to make our lives easier.\n",
    "train_df = train_df.drop(['comments'], axis= 1)\n",
    "train_df = train_df.drop(['state'], axis= 1)\n",
    "train_df = train_df.drop(['Timestamp'], axis= 1)\n",
    "\n",
    "# Assign default values for each data type\n",
    "defaultInt = 0\n",
    "defaultString = 'NaN'\n",
    "defaultFloat = 0.0\n",
    "\n",
    "# Create lists by data tpe\n",
    "intFeatures = ['Age']\n",
    "stringFeatures = ['Gender', 'Country', 'self_employed', 'family_history', 'treatment', 'work_interfere',\n",
    "                 'no_employees', 'remote_work', 'tech_company', 'anonymity', 'leave', 'mental_health_consequence',\n",
    "                 'phys_health_consequence', 'coworkers', 'supervisor', 'mental_health_interview', 'phys_health_interview',\n",
    "                 'mental_vs_physical', 'obs_consequence', 'benefits', 'care_options', 'wellness_program',\n",
    "                 'seek_help']\n",
    "floatFeatures = []\n",
    "\n",
    "# Clean the NaN's\n",
    "for feature in train_df:\n",
    "    if feature in intFeatures:\n",
    "        train_df[feature] = train_df[feature].fillna(defaultInt)\n",
    "    elif feature in stringFeatures:\n",
    "        train_df[feature] = train_df[feature].fillna(defaultString)\n",
    "    elif feature in floatFeatures:\n",
    "        train_df[feature] = train_df[feature].fillna(defaultFloat)\n",
    "    else:\n",
    "        print('Error: Feature %s not recognized.' % feature)\n",
    "\n",
    "#clean 'Gender'\n",
    "#Slower case all columm's elements\n",
    "gender = train_df['Gender'].str.lower()\n",
    "#print(gender)\n",
    "\n",
    "#Select unique elements\n",
    "gender = train_df['Gender'].unique()\n",
    "\n",
    "#Made gender groups\n",
    "male_str = [\"male\", \"m\", \"male-ish\", \"maile\", \"mal\", \"male (cis)\", \"make\", \"male \", \"man\",\"msle\", \"mail\", \"malr\",\"cis man\", \"Cis Male\", \"cis male\"]\n",
    "trans_str = [\"trans-female\", \"something kinda male?\", \"queer/she/they\", \"non-binary\",\"nah\", \"all\", \"enby\", \"fluid\", \"genderqueer\", \"androgyne\", \"agender\", \"male leaning androgynous\", \"guy (-ish) ^_^\", \"trans woman\", \"neuter\", \"female (trans)\", \"queer\", \"ostensibly male, unsure what that really means\"]\n",
    "female_str = [\"cis female\", \"f\", \"female\", \"woman\",  \"femake\", \"female \",\"cis-female/femme\", \"female (cis)\", \"femail\"]\n",
    "\n",
    "for (row, col) in train_df.iterrows():\n",
    "\n",
    "    if str.lower(col.Gender) in male_str:\n",
    "        train_df['Gender'].replace(to_replace=col.Gender, value='male', inplace=True)\n",
    "\n",
    "    if str.lower(col.Gender) in female_str:\n",
    "        train_df['Gender'].replace(to_replace=col.Gender, value='female', inplace=True)\n",
    "\n",
    "    if str.lower(col.Gender) in trans_str:\n",
    "        train_df['Gender'].replace(to_replace=col.Gender, value='trans', inplace=True)\n",
    "\n",
    "#Get rid of bullshit\n",
    "stk_list = ['A little about you', 'p']\n",
    "train_df = train_df[~train_df['Gender'].isin(stk_list)]\n",
    "\n",
    "#complete missing age with mean\n",
    "train_df['Age'].fillna(train_df['Age'].median(), inplace = True)\n",
    "\n",
    "# Fill with media() values < 18 and > 120\n",
    "s = pd.Series(train_df['Age'])\n",
    "s[s<18] = train_df['Age'].median()\n",
    "train_df['Age'] = s\n",
    "s = pd.Series(train_df['Age'])\n",
    "s[s>120] = train_df['Age'].median()\n",
    "train_df['Age'] = s\n",
    "\n",
    "#Ranges of Age\n",
    "train_df['age_range'] = pd.cut(train_df['Age'], [0,20,30,65,100], labels=[\"0-20\", \"21-30\", \"31-65\", \"66-100\"], include_lowest=True)\n",
    "\n",
    "#There are only 0.20% of self work_interfere so let's change NaN to \"Don't know\n",
    "#Replace \"NaN\" string from defaultString\n",
    "\n",
    "train_df['work_interfere'] = train_df['work_interfere'].replace([defaultString], 'Don\\'t know' )\n",
    "\n",
    "#Encoding data\n",
    "labelDict = {}\n",
    "for feature in train_df:\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    le.fit(train_df[feature])\n",
    "    le_name_mapping = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "    train_df[feature] = le.transform(train_df[feature])\n",
    "    # Get labels\n",
    "    labelKey = 'label_' + feature\n",
    "    labelValue = [*le_name_mapping]\n",
    "    labelDict[labelKey] =labelValue\n",
    "\n",
    "#Get rid of 'Country'\n",
    "train_df = train_df.drop(['Country'], axis= 1)\n",
    "\n",
    "# Scaling Age\n",
    "scaler = MinMaxScaler()\n",
    "train_df['Age'] = scaler.fit_transform(train_df[['Age']])\n",
    "\n",
    "# define X and y\n",
    "feature_cols = ['Age', 'Gender', 'family_history', 'benefits', 'care_options', 'anonymity', 'leave', 'work_interfere']\n",
    "X = train_df[feature_cols]\n",
    "y = train_df.treatment\n",
    "\n",
    "# split X and y into training and testing sets\n",
    "X_test, y_test = X, y\n",
    "\n",
    "# Transform pandas dataframe to torch tensor for DL\n",
    "\n",
    "x_test_data = torch.from_numpy(X_test.values)\n",
    "x_test_data = x_test_data.float()\n",
    "\n",
    "y_test_data = []\n",
    "for data in y_test.values:\n",
    "    y_test_data.append([data])\n",
    "y_test_data = torch.tensor(y_test_data).float()\n",
    "\n",
    "print(\"VALIDATION SET HAS BEEN CLEANED\")\n",
    "\n",
    "########## END DATA CLEANING ###############\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "residential-shelf",
   "metadata": {},
   "source": [
    "# For the Training follow the Number's Sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "absolute-appraisal",
   "metadata": {},
   "source": [
    "## 1. The Researcher Generated the model and saves it at \"/../model.pt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "intermediate-confidentiality",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# models\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.autograd import Variable\n",
    "import os\n",
    "import sys\n",
    "\n",
    "from opacus import PrivacyEngine\n",
    "\n",
    "# The Researcher generates the model\n",
    "\n",
    "model = nn.Sequential(\n",
    "            nn.Linear(8, 4),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(4, 2),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(2, 1),\n",
    "            nn.Sigmoid()\n",
    ")\n",
    "\n",
    "torch.save(model, \"../model.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "second-nursing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the model.pt to Base64 text and Send it to the hospital\n",
    "\n",
    "# cwd = os.getcwd()\n",
    "\n",
    "# if message[\"connection_id\"] == self.trusted_connection_ids[self.current_learner_index]:\n",
    "#     self.current_learner_index += 1\n",
    "\n",
    "#     if self.current_learner_index != len(self.trusted_connection_ids):\n",
    "#         self.log(\"Still learning\")\n",
    "#         self.current_model_file = cwd + \"/model/part_trained_\" + str(self.current_learner_index) + \".pt\"\n",
    "#         try:\n",
    "#             f = open(self.current_model_file, \"wb+\")\n",
    "#             byte_message = bytes.fromhex(message[\"content\"])\n",
    "#             f.write(byte_message)\n",
    "#             f.close()\n",
    "#         except Exception as e:\n",
    "#             self.log(\"Error writing file\", e)\n",
    "#             return\n",
    "#         # msg = await prompt(\"Continue Learning? Y/N \")\n",
    "#         next_learner_connection_id = self.trusted_connection_ids[self.current_learner_index]\n",
    "#         self.log(\"Continue Learning\", next_learner_connection_id)\n",
    "#         await validate_model(self.current_model_file)\n",
    "#         await self.admin_POST(\n",
    "#             f\"/connections/{next_learner_connection_id}/send-message\",\n",
    "#             {\"content\": message[\"content\"]}\n",
    "#         )\n",
    "#     else:\n",
    "#         self.log(\"Learning complete\")\n",
    "#         self.current_model_file = cwd + \"/model/trained_model.pt\"\n",
    "#         try:\n",
    "#             f = open(self.current_model_file, \"wb+\")\n",
    "#             # self.log(bytes.fromhex(message[\"content\"]))\n",
    "#             byte_message = bytes.fromhex(message[\"content\"])\n",
    "\n",
    "#             f.write(byte_message)\n",
    "#             f.close()\n",
    "#             await validate_model(self.current_model_file)\n",
    "#         except Exception as e:\n",
    "#             self.log(\"Error writing file\", e)\n",
    "#             return\n",
    "#         self.learning_complete.set_result(True)\n",
    "\n",
    "# else:\n",
    "#     self.log(\"Expecting Message from the current learner hospital:\", self.trusted_connection_ids[self.current_learner_index])\n",
    "#     self.log(\"Received message:\", message[\"content\"], message[\"connection_id\"])\n",
    "\n",
    "# b64_invite = None\n",
    "# try:\n",
    "#     url = urlparse(details)\n",
    "#     query = url.query\n",
    "#     if query and \"c_i=\" in query:\n",
    "#         pos = query.index(\"c_i=\") + 4\n",
    "#         b64_invite = query[pos:]\n",
    "#     else:\n",
    "#         b64_invite = details\n",
    "# except ValueError:\n",
    "#     b64_invite = details\n",
    "\n",
    "# if b64_invite:\n",
    "#     try:\n",
    "#         invite_json = base64.urlsafe_b64decode(b64_invite)\n",
    "#         details = invite_json.decode(\"utf-8\")\n",
    "#     except binascii.Error:\n",
    "#         pass\n",
    "#     except UnicodeDecodeError:\n",
    "#         pass\n",
    "\n",
    "# if details:\n",
    "#     try:\n",
    "#         json.loads(details)\n",
    "#         break\n",
    "#     except json.JSONDecodeError as e:\n",
    "#         log_msg(\"Invalid invitation:\", str(e))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acoustic-nitrogen",
   "metadata": {},
   "source": [
    "## 3. The Researcher receives the trained model at \"/../trained_model.pt\" and validates it using its own validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bibliographic-debut",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HOSPITAL MODEL LOADED\n",
      "\n",
      "PRINTING PARAMETERS:\n",
      "\n",
      "\n",
      "Sequential(\n",
      "  (0): Linear(in_features=8, out_features=4, bias=True)\n",
      "  (1): Sigmoid()\n",
      "  (2): Linear(in_features=4, out_features=2, bias=True)\n",
      "  (3): Sigmoid()\n",
      "  (4): Linear(in_features=2, out_features=1, bias=True)\n",
      "  (5): Sigmoid()\n",
      ")\n",
      "\n",
      "\n",
      "0.weight tensor([[ 1.5149,  1.4357, -0.7174,  0.3806,  0.3705,  1.1451, -1.0300, -4.0701],\n",
      "        [-2.1123,  1.6906, -1.8210, -0.3734, -0.5095, -1.0946, -1.4837,  1.5619],\n",
      "        [-0.2669,  0.9192, -2.6004, -0.3604, -0.9123, -0.4561,  1.5589, -0.5680],\n",
      "        [-0.5884,  0.8660,  0.6667, -1.6752,  0.4187,  0.8137,  1.2785, -2.8669]])\n",
      "0.bias tensor([2.0214, 1.1634, 0.6690, 0.6215])\n",
      "2.weight tensor([[ 4.0814,  2.8046,  1.8664,  2.8660],\n",
      "        [-2.4376, -1.6406, -0.7205, -2.2948]])\n",
      "2.bias tensor([-2.9719,  1.7671])\n",
      "4.weight tensor([[-6.6559,  4.7370]])\n",
      "4.bias tensor([2.0326])\n",
      "\n",
      "\n",
      "\n",
      "HOSPITAL IS VALIDATING\n",
      "Model loss on validation set:  tensor(-5.6757, grad_fn=<SumBackward0>)\n",
      "Confusion Matrix:\n",
      "                Actual_True, Actual_False \n",
      " Predicted_True     115    |      37     \n",
      " Predicted_False    29      |       77     \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Receive the Trained model.pt from the hospital and validate it\n",
    "\n",
    "# Pull in model\n",
    "\n",
    "model_dir = os.getcwd() + \"/../trained_model.pt\"\n",
    "\n",
    "model = torch.load(model_dir)\n",
    "\n",
    "print(\"HOSPITAL MODEL LOADED\")\n",
    "print(\"\\nPRINTING PARAMETERS:\\n\\n\")\n",
    "\n",
    "\n",
    "print(model)\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(name, param.data)\n",
    "\n",
    "# Validation Logic\n",
    "print(\"\\n\\n\\nHOSPITAL IS VALIDATING\")\n",
    "\n",
    "#BINARIZE PREDICTION FOR CONFUSION MATRIX\n",
    "\n",
    "pred = []\n",
    "\n",
    "for data in  model(x_test_data):\n",
    "    if data > .5:\n",
    "        pred.append(1)\n",
    "    else:\n",
    "        pred.append(0)\n",
    "\n",
    "\n",
    "confusion = metrics.confusion_matrix(pred, y_test_data)\n",
    "\n",
    "print(\"Model loss on validation set: \", (model(x_test_data) - y_test_data).sum())\n",
    "print(\"Confusion Matrix:\\n                Actual_True, Actual_False \\n Predicted_True    \",confusion[1][1],\"   |     \",confusion[1][0],\"    \\n Predicted_False   \",confusion[0][1],\"     |      \",confusion[0][0],\"    \\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "minimal-watts",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Send the model to the next Hospital\n",
    "# Receive the Trained Model and Validate again\n",
    "# Repeat until all Hospitals Trained the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "serial-wallace",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = await agent_controller.terminate()\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
